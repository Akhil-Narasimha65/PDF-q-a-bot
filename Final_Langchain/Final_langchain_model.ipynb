{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29756874-a5db-42ab-812d-06d8b9ff7576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: who is the  top perfomer in terms of sales\n",
      "Answer: Ben Cohen, a Spec C in New York, is the top performer in terms of sales. He made 4 year-to-date calls, resulting in 35 sales and 4 samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import re\n",
    "\n",
    "# Set your OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "# Load and process the PDF\n",
    "file_path = r\"C:\\Users\\AkhilNarasimhaS\\Downloads\\DUMMY_TABLE_TO_TEXT.pdf\"\n",
    "pdf_reader = PyPDFLoader(file_path)\n",
    "documents = pdf_reader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "# Create vector store\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db = FAISS.from_documents(documents=chunks, embedding=embeddings)\n",
    "\n",
    "# Define a more specific prompt\n",
    "AGGREGATION_PROMPT = PromptTemplate.from_template(\"\"\"\n",
    "Given the following conversation and a followup question, rephrase the followup question to be a standalone question.\n",
    "If the question requires any calculations or aggregations, please perform them and show your work.\n",
    "Make sure to filter the data based on any specified conditions (e.g., region, person, division, territory).\n",
    "Provide a step-by-step breakdown of your calculations.\n",
    "\n",
    "Chat History: {chat_history}\n",
    "Follow up Input: {question}\n",
    "\n",
    "Standalone question with calculations (if needed):\n",
    "\"\"\")\n",
    "\n",
    "# Initialize the ConversationalRetrievalChain\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=db.as_retriever(),\n",
    "    condense_question_prompt=AGGREGATION_PROMPT,\n",
    "    return_source_documents=True,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "def extract_numbers_with_context(text):\n",
    "    \"\"\"Extract numbers along with their preceding words for context.\"\"\"\n",
    "    # Updated pattern to match only two groups: context and the number\n",
    "    pattern = r'([A-Za-z\\s]+):\\s*(\\d+(?:\\.\\d+)?)'\n",
    "    matches = re.findall(pattern, text)\n",
    "    return matches\n",
    "\n",
    "def post_process_aggregation(question, answer):\n",
    "    \"\"\"Post-process the answer for aggregation questions with improved filtering.\"\"\"\n",
    "    lower_question = question.lower()\n",
    "    \n",
    "    # Extract numbers and context\n",
    "    numbers_with_context = extract_numbers_with_context(answer)\n",
    "    \n",
    "    # Extract the filter condition from the question\n",
    "    filter_words = [\"region\", \"person\", \"division\", \"territory\", \"representative\"]\n",
    "    filter_condition = next((word for word in filter_words if word in lower_question), None)\n",
    "    \n",
    "    if filter_condition:\n",
    "        filter_value_match = re.search(fr\"{filter_condition}\\s+(\\w+)\", lower_question, re.IGNORECASE)\n",
    "        if filter_value_match:\n",
    "            filter_value = filter_value_match.group(1).lower()\n",
    "            filtered_numbers = [float(num) for context, num in numbers_with_context \n",
    "                                if filter_value in context.lower()]\n",
    "            \n",
    "            if filtered_numbers:\n",
    "                total = sum(filtered_numbers)\n",
    "                return f\"The total sales for {filter_condition} '{filter_value.capitalize()}' is {total}. Details: {answer}\"\n",
    "            else:\n",
    "                return f\"No specific data found for {filter_condition} '{filter_value.capitalize()}'. Raw answer: {answer}\"\n",
    "    \n",
    "    # If no filter condition or filtered results are found\n",
    "    if numbers_with_context:\n",
    "        total = sum(float(num) for _, num in numbers_with_context)\n",
    "        return f\"The total of all sales mentioned is {total}. This may not be specific to your query. Details: {answer}\"\n",
    "    \n",
    "    return answer\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "def ask_question(query):\n",
    "    try:\n",
    "        result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "        processed_answer = post_process_aggregation(query, result['answer'])\n",
    "        \n",
    "        # Append the new question-answer pair to the chat history as a tuple\n",
    "        chat_history.append((query, processed_answer))\n",
    "        \n",
    "        return processed_answer\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred while processing your question: {str(e)}\"\n",
    "\n",
    "# Example usage\n",
    "queries = [\n",
    "    \"who is the  top perfomer in terms of sales\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"Question: {query}\")\n",
    "    answer = ask_question(query)\n",
    "    print(f\"Answer: {answer}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e2d858-da54-4c5d-a7c8-927b5d03f2dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bbebd6-dd69-4552-9f4d-33f1b27d1a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a050d80-70f7-49cc-a279-a12e3d6c11a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
